{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d2e42d-a935-4dd1-8ba5-4c4d5e56aec4",
   "metadata": {},
   "source": [
    "# ChatGPT or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e335464-c9dd-40c4-a8f7-f3a98e68c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import RocCurveDisplay, auc, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6419f96-a695-469b-9fd4-b2e49322ff60",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b242c-bea6-44a3-9a5f-6b77ab4c2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dad742-31a0-4d02-9325-b6bbf8c3f7a1",
   "metadata": {},
   "source": [
    "### Data Importation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d64b1-8f4d-4da8-bf20-846dbc49ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"s3://{YOUR_BUCKET}/sentence_level_data.csv\",\n",
    "    index_col=[0],\n",
    "    storage_options={\n",
    "        \"key\": \"AWS_ACCESS_KEY\",\n",
    "        \"secret\": \"AWS_SECRET_ACCESS_KEY\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1774eaa-03a6-4f12-9a66-4556e8a4a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Clean the text.\n",
    "\n",
    "    :param s: (str)\n",
    "    :return: str\n",
    "    \"\"\"\n",
    "    return s.lower().translate(s.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "df[\"cleaned_setence\"] = df[\"sentence\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e3042-bfe3-4e4f-a98c-8f4dbeb8ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "\n",
    "lemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83737d-fd72-4d7b-8847-e3762ff1b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(s: str, lemmer: WordNetLemmatizer) -> str:\n",
    "    \"\"\"Lemmatize the text.\n",
    "\n",
    "    :param s: (str)\n",
    "    :param stemmer: (PorterStemmer)\n",
    "    :return: (str)\n",
    "    \"\"\"\n",
    "    return \" \".join([lemmer.lemmatize(word) for word in s.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b3ec5-de79-4259-82dc-a69344a6d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized_text\"] = df[\"cleaned_setence\"].apply(lambda x: lemmatize_text(x, lemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0952980-87e8-46d4-b693-1794f9c6cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f826b-60a4-454b-9f12-245d492d91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"lemmatized_text\"],\n",
    "    df[\"class\"],\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c1838-6ce3-4dff-96bf-a8704d172da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558aa53-5d96-4558-a2b6-0cab3f43ca08",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608974e-39f6-4d07-833c-f82182dbb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b8e0e-e75b-4bf5-9b5e-beb98853d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a295361-668b-4c67-9f9f-209a142f82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57fcf6-d5c8-4759-98df-2fe3821892a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
